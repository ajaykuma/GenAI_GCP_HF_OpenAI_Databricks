{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VKcw2iCvHrTvGgwTG83zHiy4",
      "metadata": {
        "id": "VKcw2iCvHrTvGgwTG83zHiy4",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# Initialize client once\n",
        "client = AzureOpenAI(\n",
        "    api_key=\"Mykey\",\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    azure_endpoint=\"https://ak7si-mi0k5d0p-eastus2.cognitiveservices.azure.com/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WiV_xPDgJJ5_",
      "metadata": {
        "id": "WiV_xPDgJJ5_"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, deployment_name=\"gpt-4.1-nano\"):\n",
        "    \"\"\"\n",
        "    Get a chat completion from Azure OpenAI.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): User input prompt.\n",
        "        deployment_name (str): The deployment name you gave your model in Azure portal.\n",
        "\n",
        "    Returns:\n",
        "        dict: Full response object, or error dict.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=deployment_name,    # <-- This is the \"deployment name\" not the raw model name\n",
        "            messages=messages,\n",
        "            temperature=0.1,\n",
        "            top_p=0.8,\n",
        "            max_tokens=512\n",
        "        )\n",
        "\n",
        "        return response.model_dump()  # Return the full response as dict\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nl0JIGN8JhZt",
      "metadata": {
        "id": "nl0JIGN8JhZt"
      },
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"Imagine you are a detective trying to solve a mystery.\",\n",
        "    \"You arrive at the crime scene and start looking for clues.\",\n",
        "    \"You find a strange object at the crime scene. What is it?\",\n",
        "    \"How does this object relate to the crime?\",\n",
        "    \"Who do you think is the suspect and why?\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Pb9YT-O4JwXE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb9YT-O4JwXE",
        "outputId": "dfde42bb-f982-437d-bba2-c37cda8efbe8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1765636507821,
          "user_tz": -60,
          "elapsed": 4498,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Imagine you are a detective trying to solve a mystery.\n",
            "Response: {'id': 'chatcmpl-CmL03ADeBLr8itYFLshJGaL6WBFhc', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'Absolutely! Let’s dive into the mystery. \\n\\n**Scenario:**  \\nA valuable diamond necklace has gone missing from the city museum during a high-profile exhibition. The security system was functioning properly, and there are no signs of forced entry. Several people were present at the time, including the curator, a security guard, a visiting art critic, and a museum volunteer.\\n\\n**Clues so far:**  \\n- The security footage shows no one entering or leaving the exhibit room during the estimated time of theft.  \\n- The necklace was displayed in a locked glass case, which was found intact.  \\n- The security guard reports that he was patrolling nearby and didn’t see anything unusual.  \\n- The curator claims to have been in her office during the incident.  \\n- The art critic was seen arguing with the curator earlier that day.  \\n- The volunteer was restocking shelves in a different part of the museum.\\n\\n**Questions to consider:**  \\n1. Who had the opportunity to steal the necklace?  \\n2. Who might have a motive?  \\n3. Are there any inconsistencies in their stories?  \\n4. Could someone have bypassed the security measures?\\n\\n**Next steps:**  \\n- Interview each person again, focusing on their whereabouts and actions during the estimated theft time.  \\n- Examine the security footage more closely for any anomalies.  \\n- Check for fingerprints or other forensic evidence on the display case.  \\n- Investigate the background of each individual for potential motives.\\n\\nWould you like me to continue as the detective, analyze the clues further, or create a detailed suspect profile?', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636503, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 317, 'prompt_tokens': 18, 'total_tokens': 335, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
            "\n",
            "Prompt: You arrive at the crime scene and start looking for clues.\n",
            "Response: {'id': 'chatcmpl-CmL05NeoX69btFsoFmY5EfqqFhcFT', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'As I arrive at the crime scene, I begin by securing the area to ensure that evidence is preserved and that no one contaminates the scene. I carefully observe the surroundings, noting any immediate signs of disturbance, such as broken objects, bloodstains, or footprints. I document the scene with photographs and sketches from multiple angles before collecting physical evidence like fingerprints, fibers, or DNA samples. I also interview witnesses or anyone nearby who might have seen or heard something relevant. Throughout the process, I maintain a detailed log of all observations and evidence collected to assist in the investigation.', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}], 'created': 1765636505, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 116, 'prompt_tokens': 19, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}]}\n",
            "\n",
            "Prompt: You find a strange object at the crime scene. What is it?\n",
            "Response: {'id': 'chatcmpl-CmL06SMA36oxHcUvny0sWJYOL1VhD', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'Could you please provide more context or details about the crime scene? That way, I can help identify what the strange object might be.', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}], 'created': 1765636506, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}]}\n",
            "\n",
            "Prompt: How does this object relate to the crime?\n",
            "Response: {'id': 'chatcmpl-CmL06ntN744C4Pbg3T8uRiftMEEZo', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"Could you please provide more details or specify the object you're referring to? That way, I can better assist you in understanding its relation to the crime.\", 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636506, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 31, 'prompt_tokens': 16, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
            "\n",
            "Prompt: Who do you think is the suspect and why?\n",
            "Response: {'id': 'chatcmpl-CmL07XXgOw5kfGXUPTq9OJtbVzhEh', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"Could you please provide more context or details about the situation or case you're referring to? That way, I can better assist you in analyzing the suspect or providing relevant insights.\", 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636507, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 35, 'prompt_tokens': 17, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for prompt in prompts:\n",
        "    response = get_completion(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ah6xPCbuKF0Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ah6xPCbuKF0Q",
        "outputId": "e97c7fac-4892-468c-ab42-3f6f14aa94e0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1765636518717,
          "user_tz": -60,
          "elapsed": 3731,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Imagine you are a detective trying to solve a mystery.\n",
            "Response: {'id': 'chatcmpl-CmL0FIb8wqzdje0ViuR70ueVNCqYV', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"Absolutely! Let's dive into this mystery together. \\n\\n**Scenario:**  \\nA valuable diamond necklace has gone missing from the city museum during a high-profile exhibition. The security footage shows no signs of forced entry, and the staff claims to have seen nothing suspicious. The only clues are a faint footprint near the display case and a strange, partially torn piece of fabric found on the floor.\\n\\n**As the detective, I would start by asking:**  \\n- Who had access to the exhibit during the time of the theft?  \\n- Are there any witnesses who saw someone acting suspiciously?  \\n- Can we analyze the footprint to identify the shoe size or brand?  \\n- What about the torn fabric—does it match any clothing in the staff or visitor area?  \\n- Were there any recent conflicts or disgruntled individuals connected to the museum?\\n\\n**Next steps:**  \\n- Interview staff and visitors present during the event.  \\n- Examine the security footage more closely for any overlooked details.  \\n- Send the footprint and fabric samples to the lab for analysis.  \\n- Review the museum’s access logs and security protocols.\\n\\n**Your turn:**  \\nWould you like me to continue with a suspect profile, develop a theory, or perhaps craft a detailed plan to catch the culprit?\", 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636515, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 253, 'prompt_tokens': 18, 'total_tokens': 271, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
            "\n",
            "Prompt: You arrive at the crime scene and start looking for clues.\n",
            "Response: {'id': 'chatcmpl-CmL0G3AiZ4sUGos38DBvV8XNnPPJK', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'As I arrive at the crime scene, I begin by securing the area to ensure that evidence is preserved and that no one contaminates the scene. I carefully observe the surroundings, noting any immediate signs of disturbance, such as broken objects, bloodstains, or footprints. I document the scene with photographs from multiple angles before collecting any physical evidence. I look for items like weapons, fingerprints, footprints, or personal belongings that might provide clues. I also pay attention to the position of the victim and any potential witnesses or surveillance devices nearby. Every detail could be crucial in solving the case.', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}], 'created': 1765636516, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 118, 'prompt_tokens': 19, 'total_tokens': 137, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}]}\n",
            "\n",
            "Prompt: You find a strange object at the crime scene. What is it?\n",
            "Response: {'id': 'chatcmpl-CmL0Hex0mIS2Iwny1wlDXeg5FQqk2', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'Could you please provide more context or details about the crime scene? That way, I can help identify what the strange object might be.', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}], 'created': 1765636517, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}]}\n",
            "\n",
            "Prompt: How does this object relate to the crime?\n",
            "Response: {'id': 'chatcmpl-CmL0Hzo4YVNCosmNG0MZ5HI12FyHF', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"Could you please provide more details or specify the object you're referring to? That way, I can better assist you in understanding its relation to the crime.\", 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636517, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 31, 'prompt_tokens': 16, 'total_tokens': 47, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
            "\n",
            "Prompt: Who do you think is the suspect and why?\n",
            "Response: {'id': 'chatcmpl-CmL0IMidZ6kpND919SUVk3E43Cgug', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"Could you please provide more context or details about the situation or case you're referring to? That way, I can better assist you in analyzing the suspect.\", 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636518, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 31, 'prompt_tokens': 17, 'total_tokens': 48, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for prompt in prompts:\n",
        "    response = get_completion(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1FC--falKi_7",
      "metadata": {
        "id": "1FC--falKi_7"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "let's analyze the sentiment of the review step by step\n",
        "\n",
        "1. Identify the Positive aspect of the review and give a score from 10\n",
        "2. Identify the Negative aspect of the review and give a score from 10\n",
        "3. Weight the positive and negative aspect to determine the overall sentiment.\n",
        "4. provide the final sentiment classification with justification for scores used in above steps.\n",
        "\n",
        "Review: \"The product is very well designed product\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nLdOToLGLnm4",
      "metadata": {
        "id": "nLdOToLGLnm4"
      },
      "outputs": [],
      "source": [
        "response = get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bmkmNpZiLqry",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmkmNpZiLqry",
        "outputId": "96ba6944-9e0a-4130-ec26-7812d62c7dbe",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1765636530671,
          "user_tz": -60,
          "elapsed": 395,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'chatcmpl-CmL0O8sUJSd8zMf8WieTlKecaky5A', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': 'Let\\'s analyze the review step by step:\\n\\n**1. Identify the Positive aspect of the review and give a score from 10**\\n\\n- The review states: \"The product is very well designed product.\"\\n- The positive aspect is the design quality, which is described as \"very well designed.\"\\n- This indicates a strong positive sentiment toward the design.\\n\\n**Score:** 8/10\\n\\n**2. Identify the Negative aspect of the review and give a score from 10**\\n\\n- The review does not mention any negative aspects.\\n- There are no complaints or criticisms present.\\n\\n**Score:** 0/10\\n\\n**3. Weight the positive and negative aspects to determine overall sentiment**\\n\\n- Since the positive aspect is strong (8/10) and negative is absent (0/10), the overall sentiment leans positive.\\n- The absence of negatives suggests the review is primarily positive.\\n\\n**4. Final sentiment classification with justification**\\n\\n- **Sentiment:** Positive\\n- **Justification:** The review highlights a strong positive aspect (design quality) with a high score, and no negative points are mentioned. Therefore, the overall sentiment is clearly positive, supported by the high positive score and zero negative score.\\n\\n**Final conclusion:** The review is predominantly positive, emphasizing the well-designed nature of the product.', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1765636524, 'model': 'gpt-4.1-nano-2025-04-14', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_03e44fcc34', 'usage': {'completion_tokens': 260, 'prompt_tokens': 95, 'total_tokens': 355, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fBui_PtqLtBZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBui_PtqLtBZ",
        "outputId": "80604052-f988-4526-9f8a-0fd83262d393"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-C8dbt1OuZzviO2alnDAhM2tlltzFm',\n",
              " 'choices': [{'finish_reason': 'stop',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'message': {'content': 'Let\\'s analyze the sentiment of the review step by step:\\n\\n### Step 1: Identify the Positive Aspect\\n- **Positive Aspect**: The review states that \"The product is very well designed.\"\\n- **Score**: 9/10. This score reflects a strong positive sentiment due to the use of \"very well designed,\" which indicates high satisfaction with the design quality.\\n\\n### Step 2: Identify the Negative Aspect\\n- **Negative Aspect**: There are no explicit negative aspects mentioned in the review.\\n- **Score**: 0/10. Since there are no negative comments, the score is the lowest possible.\\n\\n### Step 3: Weight the Positive and Negative Aspects\\n- **Weighted Score Calculation**: \\n  - Positive Score: 9/10\\n  - Negative Score: 0/10\\n  - Overall Sentiment Score = (Positive Score - Negative Score) = 9 - 0 = 9/10\\n\\n### Step 4: Final Sentiment Classification\\n- **Final Sentiment Classification**: Positive\\n- **Justification**: The review overwhelmingly expresses a positive sentiment with a high score for the positive aspect and no negative comments. The overall sentiment score of 9/10 indicates strong approval of the product\\'s design, leading to a classification of \"Positive.\" \\n\\nIn conclusion, the review reflects a very favorable opinion of the product, primarily focusing on its design quality.',\n",
              "    'refusal': None,\n",
              "    'role': 'assistant',\n",
              "    'annotations': [],\n",
              "    'audio': None,\n",
              "    'function_call': None,\n",
              "    'tool_calls': None},\n",
              "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
              "    'protected_material_code': {'filtered': False, 'detected': False},\n",
              "    'protected_material_text': {'filtered': False, 'detected': False},\n",
              "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
              "    'violence': {'filtered': False, 'severity': 'safe'}}}],\n",
              " 'created': 1756174921,\n",
              " 'model': 'gpt-4o-mini-2024-07-18',\n",
              " 'object': 'chat.completion',\n",
              " 'service_tier': None,\n",
              " 'system_fingerprint': 'fp_efad92c60b',\n",
              " 'usage': {'completion_tokens': 288,\n",
              "  'prompt_tokens': 95,\n",
              "  'total_tokens': 383,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'prompt_filter_results': [{'prompt_index': 0,\n",
              "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
              "    'jailbreak': {'filtered': False, 'detected': False},\n",
              "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
              "    'violence': {'filtered': False, 'severity': 'safe'}}}]}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bCHlhhSUL4nF",
      "metadata": {
        "id": "bCHlhhSUL4nF"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "let's sort the values of the list step by step\n",
        "\n",
        "1. Start with the unsorted list.\n",
        "2. Compare each elements and find the smallest value.\n",
        "3. Place the samllest value in the first position.\n",
        "4. Repeat the process for all the remaming elements.\n",
        "5. provide the sorted list.\n",
        "\n",
        "Sort the list : [3,1,4,6,5,9,2]\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rwY12Ul0MMhs",
      "metadata": {
        "id": "rwY12Ul0MMhs"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "\n",
        "\"You have 12 identical-looking balls, but one is either heavier or lighter.\n",
        "You have a balance scale and can only use it three times.\n",
        "Explain step-by-step how you can find the odd ball and determine whether it is heavier or lighter.\n",
        "Think through the problem carefully and explain your reasoning in detail before giving the final answer.\"\n",
        "\n",
        "\"\"\"\n",
        "response = get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IGFmVJiWM8-C",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGFmVJiWM8-C",
        "outputId": "df35bf4e-408b-4c1e-a2f4-a337db60fae2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-C8dhKgYZQK5tMQncPza4Z92uUhSSs',\n",
              " 'choices': [{'finish_reason': 'length',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'message': {'content': \"To solve the problem of identifying the odd ball among 12 identical-looking balls, where one ball is either heavier or lighter, we can use a systematic approach with a balance scale. The key is to divide the balls into groups and use the results of the weighings to narrow down the possibilities. Here’s a step-by-step breakdown of the solution:\\n\\n### Step 1: Initial Grouping\\n1. **Divide the 12 balls into three groups of 4 balls each**: Let's label the balls as A1, A2, A3, A4 (Group A), B1, B2, B3, B4 (Group B), and C1, C2, C3, C4 (Group C).\\n\\n### Step 2: First Weighing\\n2. **Weigh Group A against Group B**:\\n   - **Case 1**: If the scales balance, then the odd ball is in Group C (C1, C2, C3, C4).\\n   - **Case 2**: If Group A is heavier, then the odd ball is either in Group A (and heavier) or in Group B (and lighter).\\n   - **Case 3**: If Group B is heavier, then the odd ball is either in Group B (and heavier) or in Group A (and lighter).\\n\\n### Step 3: Second Weighing\\nNow, we will analyze each case separately.\\n\\n#### Case 1: A = B (Odd ball is in Group C)\\n3. **Weigh C1, C2 against C3, C4**:\\n   - If they balance, then the odd ball is not among C1, C2, C3, or C4, which is impossible since we know one is odd. So, this case will not occur.\\n   - If C1, C2 is heavier, then one of C1 or C2 is heavier, or one of C3 or C4 is lighter.\\n   - If C3, C4 is heavier, then one of C3 or C4 is heavier, or one of C1 or C2 is lighter.\\n\\n#### Case 2: A > B (Odd ball is in A or B)\\n4. **Weigh A1, A2, B1 against A3, A4, B2**:\\n   - If they balance, then the odd ball is either B3 or B4 (and lighter) or A1, A2 (and heavier).\\n   - If\",\n",
              "    'refusal': None,\n",
              "    'role': 'assistant',\n",
              "    'annotations': [],\n",
              "    'audio': None,\n",
              "    'function_call': None,\n",
              "    'tool_calls': None},\n",
              "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
              "    'protected_material_code': {'filtered': False, 'detected': False},\n",
              "    'protected_material_text': {'filtered': False, 'detected': False},\n",
              "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
              "    'violence': {'filtered': False, 'severity': 'safe'}}}],\n",
              " 'created': 1756175258,\n",
              " 'model': 'gpt-4o-mini-2024-07-18',\n",
              " 'object': 'chat.completion',\n",
              " 'service_tier': None,\n",
              " 'system_fingerprint': 'fp_efad92c60b',\n",
              " 'usage': {'completion_tokens': 512,\n",
              "  'prompt_tokens': 74,\n",
              "  'total_tokens': 586,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'prompt_filter_results': [{'prompt_index': 0,\n",
              "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
              "    'jailbreak': {'filtered': False, 'detected': False},\n",
              "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
              "    'violence': {'filtered': False, 'severity': 'safe'}}}]}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "__o766f5NCpZ",
      "metadata": {
        "id": "__o766f5NCpZ"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "Let's consider which is heavier: 1000 feathers or a 30-pound weight.\n",
        "I'll think through this in a few different ways and then decide which answer seems most consistent.\n",
        "\n",
        "1. First line of reasoning: A single feather is very light, almost weightless.\n",
        "So, 1000 feathers might still be quite light, possibly lighter than a 30-pound weight.\n",
        "\n",
        "2. Second line of reasoning: 1000 is a large number, and when you add up the weight of so many feathers,\n",
        "it could be quite heavy. Maybe it's heavier than a 30-pound weight.\n",
        "\n",
        "3. Third line of reasoning: The average weight of a feather is very small. Even 1000 feathers would not add up to 30 pounds.\n",
        "\n",
        "Considering these reasonings, the most consistent answer is:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0I6UQ_NvQI",
      "metadata": {
        "id": "6a0I6UQ_NvQI"
      },
      "outputs": [],
      "source": [
        "response = get_completion(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lq4_40kdNz9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq4_40kdNz9f",
        "outputId": "71951bb1-59a2-48dd-fd1e-0ba8759674e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-C8dkxSA7cAffKunmMhiYz1UqCmwJj',\n",
              " 'choices': [{'finish_reason': 'stop',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'message': {'content': 'The most consistent answer is that 1000 feathers are lighter than a 30-pound weight. While a single feather is indeed very light, even when you multiply that by 1000, the total weight of the feathers would still be significantly less than 30 pounds. Therefore, the 30-pound weight is heavier.',\n",
              "    'refusal': None,\n",
              "    'role': 'assistant',\n",
              "    'annotations': [],\n",
              "    'audio': None,\n",
              "    'function_call': None,\n",
              "    'tool_calls': None},\n",
              "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
              "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
              "    'violence': {'filtered': False, 'severity': 'safe'}}}],\n",
              " 'created': 1756175483,\n",
              " 'model': 'gpt-4o-mini-2024-07-18',\n",
              " 'object': 'chat.completion',\n",
              " 'service_tier': None,\n",
              " 'system_fingerprint': 'fp_efad92c60b',\n",
              " 'usage': {'completion_tokens': 65,\n",
              "  'prompt_tokens': 167,\n",
              "  'total_tokens': 232,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'prompt_filter_results': [{'prompt_index': 0,\n",
              "   'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'},\n",
              "    'jailbreak': {'filtered': False, 'detected': False},\n",
              "    'self_harm': {'filtered': False, 'severity': 'safe'},\n",
              "    'sexual': {'filtered': False, 'severity': 'safe'},\n",
              "    'violence': {'filtered': False, 'severity': 'safe'}}}]}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lwHLLhIDN1Rp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwHLLhIDN1Rp",
        "outputId": "dc617539-f441-48ad-c2ee-dab9814b845d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z-JFzudWwLiE",
      "metadata": {
        "id": "z-JFzudWwLiE"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "templatee = \" Please write a {length} review,of the book {book_title}. \"\n",
        "\n",
        "input_variabless = [ \"length\", \"book_title\" ]\n",
        "\n",
        "# Creating the prompt template\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=input_variabless,\n",
        "    template=templatee\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A19x7WxYwVUp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A19x7WxYwVUp",
        "outputId": "d1f25eaf-74ce-4534-ad00-402b55571529"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Please write a short review,of the book  House Of Dragon. \n",
            "AI Response:\n",
            "{'id': 'chatcmpl-C9JOsuKfGicZpmxcCxIL1WRojsS5v', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': '\"House of the Dragon\" is a captivating exploration of the Targaryen dynasty, set in the rich and intricate world created by George R.R. Martin. This prequel delves into the complex relationships, political intrigue, and the fiery legacy of the Targaryens, showcasing their rise and the internal conflicts that ultimately lead to their downfall. The narrative is filled with vivid characters, each with their own ambitions and flaws, making it a compelling read for fans of epic fantasy. The book masterfully balances action and character development, immersing readers in a world of dragons, betrayal, and power struggles. Overall, \"House of the Dragon\" is a thrilling addition to the lore of Westeros, offering both depth and excitement for those eager to explore the history behind the beloved series.', 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1756335562, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_efad92c60b', 'usage': {'completion_tokens': 160, 'prompt_tokens': 22, 'total_tokens': 182, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n"
          ]
        }
      ],
      "source": [
        "formatted_prompt = prompt.format(length = \"short\", book_title = \" House Of Dragon\")\n",
        "\n",
        "print(formatted_prompt)\n",
        "\n",
        "response = get_completion(formatted_prompt)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5QWV2NU7wdZ5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QWV2NU7wdZ5",
        "outputId": "84f79134-abde-4ee5-de82-fdcf4f1020de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Give me an interesting fact about space exploration\n",
            "AI Response:\n",
            "{'id': 'chatcmpl-C9JPAnynjNu8N5M0Oa6oQFfZS65KP', 'choices': [{'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'content': \"One interesting fact about space exploration is that the Voyager 1 spacecraft, launched by NASA in 1977, is the farthest human-made object from Earth. As of now, it is over 14 billion miles away and has entered interstellar space, providing valuable data about the outer solar system and the environment beyond it. Voyager 1 carries a Golden Record, which contains sounds and images representing the diversity of life and culture on Earth, intended as a message to any extraterrestrial life that might encounter it. This makes it not only a scientific mission but also a symbolic gesture of humanity's desire to connect with the cosmos.\", 'refusal': None, 'role': 'assistant', 'annotations': [], 'audio': None, 'function_call': None, 'tool_calls': None}, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'created': 1756335580, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion', 'service_tier': None, 'system_fingerprint': 'fp_efad92c60b', 'usage': {'completion_tokens': 126, 'prompt_tokens': 15, 'total_tokens': 141, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}]}\n"
          ]
        }
      ],
      "source": [
        "jinja2_template = \"Give me an {{ adjective }} fact about {{ topic }}\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(jinja2_template, template_format = \"jinja2\" )\n",
        "\n",
        "user_question = prompt.format(adjective=\"interesting\", topic=\"space exploration\")\n",
        "\n",
        "print(user_question)\n",
        "\n",
        "response = get_completion(user_question)\n",
        "print(\"AI Response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HimcVeX8wiBr",
      "metadata": {
        "id": "HimcVeX8wiBr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Working_with_prompts.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}