{
  "cells": [
    {
      "cell_type": "code",
      "id": "E2hbfXMc7xTtPdkE45JzoOcn",
      "metadata": {
        "tags": [],
        "id": "E2hbfXMc7xTtPdkE45JzoOcn"
      },
      "source": [
        "import os\n",
        "from openai import AzureOpenAI\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(\"/content/.env\")\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_version=\"2024-12-01-preview\",\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, deployment=\"gpt-4.1\"):\n",
        "    response = client.chat.completions.create(\n",
        "        model=deployment,   #Azure uses DEPLOYMENT name here\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "mNGG_WLjaaWY"
      },
      "id": "mNGG_WLjaaWY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_completion(\"Explain transformers in simple terms\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLQfR4Dibcjz",
        "outputId": "b4aad54a-2a97-4514-9023-d29938b437cc"
      },
      "id": "qLQfR4Dibcjz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here’s a simple explanation of **transformers**:\n",
            "\n",
            "---\n",
            "\n",
            "**Transformers** are a type of computer model that helps machines understand and generate language (like text or speech).\n",
            "\n",
            "**Imagine you’re reading a sentence:**  \n",
            "A transformer looks at all the words in the sentence at the same time, and figures out how each word relates to the others. This helps it understand the meaning better.\n",
            "\n",
            "**How does it work?**  \n",
            "- It pays “attention” to important words, not just the ones right next to each other.\n",
            "- It can remember context from earlier in the sentence or even earlier sentences.\n",
            "\n",
            "**Why are transformers special?**  \n",
            "- They’re really good at understanding long texts.\n",
            "- They can translate languages, answer questions, write stories, and more.\n",
            "\n",
            "**In short:**  \n",
            "Transformers are smart computer models that read and understand text by looking at all the words together and figuring out which ones matter most.\n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you want a bit more detail or an example!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using Langchain Equivalent\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "#from dotenv import load_dotenv\n",
        "#load_dotenv(\"/content/.env\")\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    deployment_name=\"gpt-4.1\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "llm.invoke(\"Explain transformers in simple terms in 25 words\").content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Y2QCehqPbgjV",
        "outputId": "1c1a5946-b250-4602-e027-b5fc7d4b16e2"
      },
      "id": "Y2QCehqPbgjV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Transformers are AI models that understand language by focusing on important words in sentences, helping computers translate, summarize, and answer questions more accurately.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_completion(\"What is 1+1?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9fA5V0QbvpF",
        "outputId": "6611d651-7afc-466c-ff83-e7473ceb451d"
      },
      "id": "s9fA5V0QbvpF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 + 1 = **2**.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Start by creating an instance of the AzureChatOpenAI class.\n",
        "chat = AzureChatOpenAI(\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    deployment_name=\"gpt-4.1\",\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "F_KN2Q0Vb-E3"
      },
      "id": "F_KN2Q0Vb-E3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "template_string = \"\"\"Translate the text that is delimited by triple backticks\n",
        "into a style that is {style}.\n",
        "text: ```{text}```\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "y_NojHalcpBc"
      },
      "id": "y_NojHalcpBc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"American English in a casual tone\"\n",
        "\n",
        "customer_email = \"\"\"\n",
        "I'm super excited about the new gaming console I bought!\n",
        "It arrived in just 2 days and I've been playing non-stop.\n",
        "Totally worth the price!\n",
        "\"\"\"\n",
        "\n",
        "customer_messages = prompt_template.format_messages(\n",
        "    style=customer_style,\n",
        "    text=customer_email\n",
        ")\n"
      ],
      "metadata": {
        "id": "BjEtJYJecodw"
      },
      "id": "BjEtJYJecodw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(customer_messages)\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHaJIY9Hc5h2",
        "outputId": "fc851ff0-7538-48f7-c74e-29b1d7c83e5e"
      },
      "id": "KHaJIY9Hc5h2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm so pumped about the new gaming console I got! It showed up in just two days, and I've been playing nonstop ever since. Definitely worth every penny!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Format a new message using a different style.\n",
        "service_reply = \"Hey there, we're glad you're enjoying your new gaming console. Game on!\"\n",
        "service_style_pirate = \"a cheerful tone that speaks in English Pirate\"\n",
        "service_messages = prompt_template.format_messages(\n",
        "    style=service_style_pirate,\n",
        "    text=service_reply\n",
        ")\n",
        "print(service_messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyTMidXsc-Ux",
        "outputId": "b0349af5-91e2-4bba-cedb-da7107dda906"
      },
      "id": "wyTMidXsc-Ux",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the text that is delimited by triple backticks\n",
            "into a style that is a cheerful tone that speaks in English Pirate.\n",
            "text: ```Hey there, we're glad you're enjoying your new gaming console. Game on!```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a response in our new style using the ChatOpenAI instance.\n",
        "service_response = chat.invoke(service_messages)\n",
        "print(service_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ypDDcpydNiL",
        "outputId": "4656e026-fafa-4f9e-cacc-ea70a9e9c3b6"
      },
      "id": "5ypDDcpydNiL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahoy matey! We be mighty pleased ye be enjoyin’ yer new gamin’ contraption. Hoist the sails and game on, yarrr!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define how we would like the output from the language model to look like.\n",
        "desired_output = {\n",
        "    \"gift\": False,\n",
        "    \"delivery_days\": 2,\n",
        "    \"price_value\": \"Totally worth the price!\"\n",
        "}\n",
        "\n",
        "# Create a customer review and a template for extracting information from the review.\n",
        "customer_review = \"\"\"\\\n",
        "I'm super excited about the new gaming console I bought! It arrived in just 2 days and I've been playing non-stop. Totally worth the price!\n",
        "\"\"\"\n",
        "\n",
        "review_template = \"\"\"\\\n",
        "For the following text, extract the following information:\n",
        "gift: Was the item purchased as a gift for someone else? \\\n",
        "Answer True if yes, False if not or unknown.\n",
        "delivery_days: How many days did it take for the product \\\n",
        "to arrive? If this information is not found, output -1.\n",
        "price_value: Extract any sentences about the value or price,\\\n",
        "and output them as a comma separated Python list.\n",
        "Format the output as JSON with the following keys:\n",
        "gift\n",
        "delivery_days\n",
        "price_value\n",
        "text: {text}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "l1n0G2bVdTTT"
      },
      "id": "l1n0G2bVdTTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain_core\n",
        "import langchain_openai"
      ],
      "metadata": {
        "id": "KmtSMLHteCbE"
      },
      "id": "KmtSMLHteCbE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import inspect"
      ],
      "metadata": {
        "id": "gy4090xYf2UZ"
      },
      "id": "gy4090xYf2UZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(langchain.__version__)\n",
        "print(inspect.getfile(langchain))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Osf7bQKevvo",
        "outputId": "7b2c4e0a-4cb4-4cef-8eea-80ec2fb33960"
      },
      "id": "9Osf7bQKevvo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.3\n",
            "/usr/local/lib/python3.12/dist-packages/langchain/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if model exists\n",
        "#import langchain.output_parsers as op\n",
        "#print(dir(op))"
      ],
      "metadata": {
        "id": "QiJ6LdV4flJU"
      },
      "id": "QiJ6LdV4flJU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOoCog9Ug_LP",
        "outputId": "f1682f76-ed4b-4eb6-de82-15ddeefaad5d"
      },
      "id": "hOoCog9Ug_LP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from pydantic import BaseModel\n"
      ],
      "metadata": {
        "id": "eBCgWE-VhYe2"
      },
      "id": "eBCgWE-VhYe2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define Pydantic model for structured output\n",
        "class ReviewAnalysis(BaseModel):\n",
        "    gift: bool\n",
        "    delivery_days: int\n",
        "    price_value: list[str]"
      ],
      "metadata": {
        "id": "Kb72b5WNh-JE"
      },
      "id": "Kb72b5WNh-JE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Start by creating an instance of the AzureChatOpenAI class.\n",
        "chat = AzureChatOpenAI(\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key=os.getenv(\"API_KEY\"),\n",
        "    api_version=\"2024-12-01-preview\",\n",
        "    deployment_name=\"gpt-4.1\",\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "85uGMLA1iA3w"
      },
      "id": "85uGMLA1iA3w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Prepare prompt template\n",
        "review_template = \"\"\"Analyze the following customer review and return a JSON object\n",
        "matching this structure:\n",
        "\n",
        "{{\n",
        "  \"gift\": true/false,\n",
        "  \"delivery_days\": int,\n",
        "  \"price_value\": [ ... ]\n",
        "}}\n",
        "\n",
        "Review:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(review_template)\n",
        "\n",
        "# Step 6: Example review text\n",
        "customer_review = \"\"\"\n",
        "I bought this gaming console as a present for my brother.\n",
        "It arrived in just 2 days, which was amazing!\n",
        "The price was a bit high, around $500, but totally worth it.\n",
        "\"\"\"\n",
        "\n",
        "# Step 7: Format messages\n",
        "messages = prompt.format_messages(text=customer_review)\n",
        "\n",
        "# Step 8: Invoke AzureChatOpenAI\n",
        "response = chat.invoke(messages)\n",
        "\n",
        "# Step 9: Parse JSON into dictionary\n",
        "try:\n",
        "    output_dict = json.loads(response.content)\n",
        "except json.JSONDecodeError:\n",
        "    print(\"Failed to parse JSON. Raw response:\")\n",
        "    print(response.content)\n",
        "    output_dict = {}\n",
        "# Step 10: Inspect results\n",
        "print(\"Raw dict output:\")\n",
        "print(output_dict)\n",
        "\n",
        "# Optional: convert to Pydantic model for type safety\n",
        "try:\n",
        "    analysis = ReviewAnalysis(**output_dict)\n",
        "except Exception as e:\n",
        "    print(\"Failed to convert to Pydantic model:\", e)\n",
        "    analysis = None\n",
        "\n",
        "if analysis:\n",
        "    print(\"\\nPydantic model output:\")\n",
        "    print(analysis)\n",
        "    print(\"Gift:\", analysis.gift)\n",
        "    print(\"Delivery days:\", analysis.delivery_days)\n",
        "    print(\"Price sentences:\", analysis.price_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtrhnGfJiIOS",
        "outputId": "86f10c19-4145-4c20-fb64-f1a38b87f406"
      },
      "id": "EtrhnGfJiIOS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw dict output:\n",
            "{'gift': True, 'delivery_days': 2, 'price_value': ['high', 'worth it']}\n",
            "\n",
            "Pydantic model output:\n",
            "gift=True delivery_days=2 price_value=['high', 'worth it']\n",
            "Gift: True\n",
            "Delivery days: 2\n",
            "Price sentences: ['high', 'worth it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence"
      ],
      "metadata": {
        "id": "U8y9W42EidU7"
      },
      "id": "U8y9W42EidU7",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2️⃣ Memory as Python list\n",
        "chat_history = []\n",
        "\n",
        "def add_to_memory(role: str, content: str):\n",
        "    chat_history.append({\"role\": role, \"content\": content})\n",
        "\n",
        "# 3️⃣ Prompt template that includes memory\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"{chat_history}\\nUser: {input}\\nAssistant:\"\n",
        ")\n",
        "\n",
        "# 4️⃣ Function to generate response with memory\n",
        "def chat_with_memory(user_input: str):\n",
        "    add_to_memory(\"user\", user_input)\n",
        "    # Flatten memory into string\n",
        "    history_str = \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in chat_history])\n",
        "    messages = prompt_template.format_messages(chat_history=history_str, input=user_input)\n",
        "    response = chat.invoke(messages)\n",
        "    add_to_memory(\"assistant\", response.content)\n",
        "    return response.content\n",
        "\n",
        "# 5️⃣ Example usage\n",
        "print(chat_with_memory(\"Hello! How are you?\"))\n",
        "print(chat_with_memory(\"Can you summarize what we talked about so far?\"))\n"
      ],
      "metadata": {
        "id": "PVqs-VXRi_Dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d649db6-f7a2-4232-bb05-47cdb745d9e2"
      },
      "id": "PVqs-VXRi_Dc",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm here and ready to help. How can I assist you today?\n",
            "Certainly! So far, you greeted me and asked how I was doing. I responded and asked how I could assist you. Then, you requested a summary of our conversation. Would you like to continue or ask about something specific?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi-stel memory aware conversation\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "def remember_step(user_input):\n",
        "    add_to_memory(\"user\", user_input)\n",
        "    return user_input\n",
        "\n",
        "def llm_step(user_input):\n",
        "    history_str = \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in chat_history])\n",
        "    messages = prompt_template.format_messages(chat_history=history_str, input=user_input)\n",
        "    response = chat.invoke(messages)\n",
        "    add_to_memory(\"assistant\", response.content)\n",
        "    return response.content\n",
        "\n",
        "sequence = RunnableSequence(remember_step, llm_step)\n",
        "\n",
        "# Run sequence\n",
        "output = sequence.invoke(\"Hello again!\")\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YQSAchhkrWl",
        "outputId": "50e3b740-48e2-4a09-8b97-fa2536f29991"
      },
      "id": "2YQSAchhkrWl",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello again! Welcome back. How can I assist you this time?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QEam4NckxxP"
      },
      "id": "9QEam4NckxxP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "ak7singhal (Jan 11, 2026, 3:12:20 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}